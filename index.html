
<!DOCTYPE html>
<html lang="en">
<head>
  <title>Explainable AI</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  <style>
    /* Remove the navbar's default margin-bottom and rounded borders */
    /* .navbar {
      margin-bottom: 0;
      border-radius: 0;
    } */

    /* Set height of the grid so .sidenav can be 100% (adjust as needed) */
    .row.content {height: auto}

    /* Set gray background color and 100% height */
    /* .sidenav {
      padding-top: 20px;
      background-color: #f1f1f1;
      height: 100%;
    } */

    /* Set black background color, white text and some padding */
    /* footer {
      background-color: #555;
      color: white;
      padding: 5px;
    } */

    /* On small screens, set height to 'auto' for sidenav and grid */
    @media screen and (max-width: 767px) {
      .sidenav {
        height: auto;
        padding: 15px;
      }
      .row.content {height:auto;}
    }
  </style>
</head>
<body>

<!-- <nav class="navbar navbar-inverse"> </nav> -->

<div class="container text-center">
    <table border="0" align="center">
      <tr>
        <td width="700" align="center" valign="middle"><h3>AAAI 2023 Tutorial</h3>
         <span class="title"><h4>Explainable AI:</h4> </span>
         <span class="title"><h5>On Explainable AI: From Theory to Motivation, Industrial Applications, XAI Coding & Engineering Practices</h5> </span>
         <span class="title"><h5>Half-day (3 hours) Tutorial</h5> </span>
         <span class="title"><h5>Tuesday, February 7th, 2023 <font color="green">(TBC)</font></h5> </span>
         <span class="title"><h5>2:00 PM – 6:00 PM (EST / New York Time) <font color="green">(TBC)</font></h5> </span>
         <span class="title"><h5>Room: Virtual <font color="green">(TBC)</font>/ Physical Room (201)</h5> </span>
         <span class="title"><h5>YouTube Link <font color="green">(TBD)</font></h5></span>
         <span class="title"><h5>Slides <font color="green">(due Feb 6th 2023)</font> - Coding Materials <font color="green">(due Feb 6th 2023)</font></h5></span>
         <!-- <span class="title"><h5><a href="https://www.youtube.com/watch?v=uFF1Ul1oM88">YouTube Link</a> </h5> </span> -->
         <!-- <span class="title"><h5> <a href="http://www-sop.inria.fr/members/Freddy.Lecue/presentation/aaai_2023_xai_tutorial.pdf">Download Slides (2023 Feb 2nd version - latest)</a> </h5></span> -->
        </td>
      </tr>
    </table>
    <p><img class="img-rounded" src="assets/images/main.png" width="100%" height="200" align="center" /></p>

</div>


<div class="container-fluid text-center">

  <div class="row content">
    <div class="col-md-1 sidenav"></div>
    <div class="col-md-10 text-left">
      <h2 align="center">Goal of the Tutorial</h2>
      <p>The goal of the tutorial is to provide answers to the following questions:</p>
      <div class="list-group">
        <a href="#" class="list-group-item">
          <h5 class="list-group-item-heading">What is explainable AI (XAI)</h5>
          <p class="list-group-item-text">What is explainable AI (XAI for short) i.e., what are explanations from the various areas of the AI community (Machine Learning, Logics, Constraint Programming, Diagnostics)? What are the metrics for explanations?</p>
        </a>

        <a href="#" class="list-group-item">
            <h5 class="list-group-item-heading">Why shall we care?</h5>
            <p class="list-group-item-text">Why is explainable AI important? even crucial in some applications? What are the motivations in elaborating AI systems which expose explanations?</p>
        </a>

        <a href="#" class="list-group-item">
              <h5 class="list-group-item-heading">Where is it critical? <font color="red">Upgraded for 2023.</font></h5>
              <p class="list-group-item-text">What are the real-world applications that are in real needs of explanations to deploy AI systems at scale?</p>
        </a>

        <a href="#" class="list-group-item">
            <h5 class="list-group-item-heading">How does it work? <font color="red">Review of Recent Appraches + Stronger focus on explaining Deep Neural Networks.</font></h5>
            <p class="list-group-item-text">What are the state-of-the-art techniques for elaborating explanation in computer vision, natural language processing? What does work well, not so well, for which data format, use case, application, industry?</p>
        </a>

        <a href="#" class="list-group-item">
            <h5 class="list-group-item-heading">How to code and engineer XAI? <font color="red">New for 2023.</font></h5>
            <p class="list-group-item-text">How to develop, adapt, re-use and engineer XAI components? Where to start from?</p>
        </a>

        <a href="#" class="list-group-item">
            <h5 class="list-group-item-heading">What did we learn? <font color="red">Upgraded for 2023.</font></h5>
            <p class="list-group-item-text">What are the lessons learned and limitations in deploying existing XAI systems? in communicating explanation to human?</p>
        </a>

        <a href="#" class="list-group-item">
            <h5 class="list-group-item-heading">What is next? <font color="red">Upgraded for 2023.</font></h5>
            <p class="list-group-item-text">What are some of the promising future directions in XAI?</p>
        </a>
      </div>
    </div>
    <div class="col-md-1 sidenav" ></div>
  </div>

  <div class="row content">
      <div class="col-md-1 sidenav"></div>
      <div class="col-md-10 text-left">
          <h2 align="center">Overview</h2>
          <p>The future of AI lies in enabling people to collaborate with machines to solve complex problems. Like any efficient collaboration, this requires good communication, trust, clarity and understanding. XAI (eXplainable AI) aims at addressing such challenges by combining the best of symbolic AI and traditional Machine Learning. Such topic has been studied for years by all different communities of AI, with different definitions, evaluation metrics, motivations and results.</p>

          <p>This tutorial is a snapshot on the work of XAI to date, and surveys the work achieved by the AI community with a focus on machine learning and symbolic AI related approaches (given the half-day format). We will motivate the needs of XAI in real-world and large-scale applications, while presenting state-of-the-art techniques, with best XAI coding and engineering practices. In the first part of the tutorial, we give an introduction to the different aspects of explanations in AI. We then focus the tutorial on two specific approaches: (i) XAI using machine learning and (ii) XAI using a combination of graph-based knowledge representation and machine learning. For both we get into the specifics of the approach, the state of the art and the research challenges for the next steps. The final part of the tutorial gives an overview of real-world ap-plications of XAI as well as best XAI coding and engineering practices, as XAI technologies are required to be seamlessly integrated in AI applications.</p>

       </div>
      <div class="col-md-1 sidenav"></div>
  </div>

  <div class="row content">
    <div class="col-md-1 sidenav"></div>
    <div class="col-md-10 text-left">
        <h2 align="center">Outline</h2>
        <h4>Part I: Introduction, Motivation & Evaluation - 20 minutes</h4>
        <p>Broad-spectrum introduction on explanation in AI. This will include describing and motivating the need for explainable AI techniques, from both theoretical and applicative standpoints. In this part we also summarize the prerequisites, and we introduce the different angles taken by the rest of the tutorial.</p>

        <h4>Part II: Explanation in AI (not only Machine Learning!) - 40 minutes</h4>
        <p>General overview of explanation in various field of AI (optimization, knowledge representation and reasoning, machine learning, search and constraint optimization, planning, natural language processing, robotics and vision) to align everyone on the various definitions of explanation. Evaluation of explainability will be also covered. The tutorial will cover most of definitions but will only go deep in the following areas: (i) Explainable Machine Learning, (ii) Explainable AI with Knowledge Graphs and Machine Learning.</p>

        <h4>Part III: Explanation for Deep Neural Networks - 40 minutes</h4>
        <p> In this section of the tutorial we address the challenge of explaining deep neural networks: from models consuming image, text and time series. </p>

        <h4>Part IV: On The Role of Knowledge Graphs in Explainable Machine Learning - 40 minutes</h4>
        <p> In this section of the tutorial we address the explanatory power of combining graph-based knowledge bases with machine learning approaches. </p>

        <h4>Part V: XAI Applications and Lessons Learnt - 40 minutes</h4>
        <p>We will review some XAI open source and commercial tools applied in real-world examples. We describe how XAI could be instantiated based on the technical and business challenge. In particular we focus on a number of use cases: (1) explaining object detection, (2) explaining obstacle detection for autonomous trains, (3) explaining flight performance, (4) an interpretable flight delay prediction system, with built-in explanation capabilities, (5) a wide-scale contract management system that predicts and explains the risk tier of corporate projects with semantic reasoning over knowledge graphs, (6) an expenses system that identifies, explains, and predict abnormal expense claims by employees of large organizations in 500+ cities, (7) an explanation system for credit decisions, (8) an explanation system for medical conditions, as well as 8 other use cases in industry.</p>

        <h4>Part VI: XAI Tools, Coding & Engineering Practices Conclusion, and Research Challenges - 40 minutes</h4>
        <p>We go through XAI coding & engineering practices by demonstrating how XAI could be integrated, and tested. This section will go through development codes, which are shared with Google Colab for easy interaction with the AAAI audience. A Google account (to access Google Colab) is required for this section.</p>

    </div>
    <div class="col-md-1 sidenav"></div>
  </div>

  <div class="row content">
    <div class="col-md-1 sidenav"></div>
    <div class="col-md-10 text-left">
        <h2 align="center">Schedule</h2>
        <h4>Part I: Introduction and Motivation - 20 minutes</h4>
        <p>[2:00pm - 2:20pm Pacific Time] <font color="green">(Confirmed)</font></p>

        <h4>Part II: Explanation in AI (not only Machine Learning!) - 40 minutes</h4>
        <p>[2:20pm - 3:00pm Pacific Time] <font color="green">(Confirmed)</font></p>

        <h4>Part III: Explanation for Deep Neural Networks - 40 minutes</h4>
        <p>[3:00pm - 3:40pm Pacific Time] <font color="green">(Confirmed)</font></p>

        <h4>Break - 20 minutes</h4>
        <p>[3:40pm - 4:00pm Pacific Time] <font color="green">(Confirmed)</font></p>

        <h4>Part IV: On The Role of Knowledge Graphs in Explainable Machine Learning - 40 minutes</h4>
        <p>[4:00pm - 4:40pm Pacific Time] <font color="green">(Confirmed)</font></p>

        <h4>Part V: XAI Applications and Lessons Learnt - 40 minutes</h4>
        <p>[4:40pm - 5:20pm Pacific Time] <font color="green">(Confirmed)</font></p>

        <h4>Part VI: XAI Tools, Coding and Engineering Practices Conclusion, and Research Challenges - 40 minutes</h4>
        <p>[5:20pm - 6:00pm Pacific Time] <font color="green">(Confirmed)</font></p>

    </div>
    <div class="col-md-1 sidenav"></div>
  </div>

  <!-- <div class="row">

      <div class="col-md-1 sidenav"></div>
      <div class="col-md-2">
          <a href="assets/images/luca.jpg" target="_blank">
            <img class="img-responsive img-circle" src="assets/images/luca.jpg" alt="Luca" >
            <div class="caption">
              <p>Luca Costabello</p>
            </div>
          </a>
      </div>
      <div class="col-md-1 sidenav"></div>
  </div> -->

  <div class="row content">
    <div class="col-md-1 sidenav">
      <!--  -->
    </div>
    <div class="col-md-10 text-left">
        <h2 align="center">Presenters</h2>

      <h4>Freddy Lecue</h4>
      <p><a href="http://www-sop.inria.fr/members/Freddy.Lecue/">Freddy Lecue</a> (PhD 2008, Habilitation 2015) is an Artificial Intelligence (AI) Research Director at J.P. Morgan in New York, USA since August 2022. He is also a research associate at INRIA, in WIMMICS, Sophia Antipolis, France. He was the Chief AI Scientist at CortAIx (Centre of Research & Technology in Artificial Intelligence eXpertise), Thales in Montreal, Canada from January 2019 till August 2022. Before joining Thales he was principal scientist and research manager in Artificial Intelligent systems, systems combining learning and reasoning capabilities, in Accenture Technology Labs, Dublin - Ireland. Before joining Accenture Labs, he was a Research Scientist at IBM Research, Smarter Cities Technology Center (SCTC) in Dublin, Ireland, and lead investigator of the Knowledge Representation and Reasoning group. His main research interests are Explainable AI systems. The application domain of his current research is Smarter Cities, with a focus on Smart Transportation and Building. In particular, he is interested in exploiting and advancing Knowledge Representation and Reasoning methods for representing and inferring actionable insight from large, noisy, heterogeneous and big data. He has over 50 publications in refereed journals and conferences related to Artificial Intelligence (AAAI, ECAI, IJCAI, IUI) and Semantic Web (ESWC, ISWC), all describing new system to handle expressive semantic representation and reasoning. He co-organized the first three workshops on semantic cities (AAAI 2012, 2014, 2015, IJCAI 2013), and the first two tutorial on smart cities at AAAI 2015 and IJCAI 2016. Prior to joining IBM, Freddy Lecue was a Research Fellow (2008-2011) with the Centre for Service Research at The University of Manchester, UK. He has been awarded by a second prize for his Ph.D thesis by the French Association for the Advancement of Artificial Intelligence in 2009, and has been recipient of the Best Research Paper Award at the ACM/IEEE Web Intelligence conference in 2008.</p>

      <h4>Pasquale Minervini</h4>
      <p><a href="http://www.neuralnoise.com">Pasquale Minervini</a> is a Lecturer in Natural Language Processing at the School of Informatics, University of Edinburgh. Previously, he was a Senior Research Fellow at UCL (2017-2022); a postdoc at the INSIGHT Centre for Data Analytics, Ireland (2016); and a postdoc at the University of Bari, Italy (2015). His research interests are in NLP and ML, with a focus on relational learning and learning from graph-structured data, solving knowledge-intensive tasks, hybrid neuro-symbolic models, compositional generalisation, and designing data-efficient and robust deep learning models. Pasquale published over 60 peer-reviewed papers in top-tier AI conferences, receiving multiple awards (including one Outstanding Paper Award at ICLR 2021), and delivered several tutorials on Explainable AI and relational learning (including four AAAI tutorials). On behalf of the University of Edinburgh and UCL, he is the Principal Investigator (PI) of the EU Horizon 2020 research grant <a href="https://cordis.europa.eu/project/id/875160">CLARIFY -- Cancer Long Survivors Artificial Intelligence Follow Up</a>, the <a href="https://web.inf.ed.ac.uk/eliai">Edinburgh Laboratory on Integrated Artificial Intelligence</a> (ELIAI) grant  <a href="https://web.inf.ed.ac.uk/eliai/projects/gradient-based-learning-of-complex-latent-structur">Gradient-based Learning of Complex Latent Structures</a>, and multiple industry grants and donations. In 2020, his team won two tracks out of three of the Efficient Open-Domain Question Answering Challenge at NeurIPS 2020. He routinely collaborates with researchers across both academia and industry. For more information about him, check his website <a href="http://www.neuralnoise.com">http://www.neuralnoise.com</a> </p>

      <h4>Riccardo Guidotti</h4>
      <p><a href="https://kdd.isti.cnr.it/people/riccardo-guidotti">Riccardo Guidotti</a> is currently a post-doc researcher at the Department of Computer Science University of Pisa, Italy and a member of the Knowledge Discovery and Data Mining Laboratory (KDDLab), a joint research group with the Information Science and Technology Institute of the National Research Council in Pisa. Riccardo Guidotti was born in 1988 in Pitigliano (GR) Italy. In 2013 and 2010 he graduated cum laude in Computer Science (MS and BS) at University of Pisa. He received the PhD in Computer Science with a thesis on Personal Data Analytics in the same institution. He won the IBM fellowship program and has been an intern in IBM Research Dublin, Ireland in 2015. His research interests are in personal data mining, clustering, explainable models, analysis of transactional data related to recipes and to migration flows.</p>

      <h4>Fosca Giannotti</h4>
      <p><a href="https://kdd.isti.cnr.it/people/giannotti-fosca">Fosca Giannotti</a> is Director of Research at the Information Science and Technology Institute “A. Faedo” of the National Research Council, Pisa, Italy. Fosca Giannotti is a scientist in Data mining and Machine Learning and Big Data Analytics. Fosca leads the Pisa KDD Lab - Knowledge Discovery and Data Mining Laboratory http://kdd.isti.cnr.it, a joint research initiative of the University of Pisa and ISTI-CNR, founded in 1994 as one of the earliest research lab centered on data mining. Fosca’s research focus is on social mining from big data: human dynamics, social networks, diffusion of innovation, privacy enhancing technology and explainable AI. She has coordinated tens of research projects and industrial collaborations. Fosca is now the coordinator of SoBigData, the European research infrastructure on Big Data Analytics and Social Mining, an ecosystem of ten cutting edge European research centres providing an open platform for interdisciplinary data science and data-driven innovation http://www.sobigdata.eu. In 2012-2015 Fosca has been general chair of the Steering board of ECML-PKDD (European conference on Machine Learning) and is currently member of the steering committee EuADS (European Association on Data Science) and of the AIIS: Italian Lab. of Artificial Intelligence and Autonomous Systems.</p>

    </div>
    <div class="col-md-1 sidenav">
      <!--  -->
    </div>
  </div>


</div>

<!-- <div class="container text-center">

</div> -->

<footer class="container-fluid text-left">
    <div class="col-md-1 sidenav">
        <!--  -->
      </div>
      <div class="col-md-10">

    <p>Please contact <a href="freddy.lecue@inria.fr">Freddy Lecue</a> if you have question.</p>
        </div>
    <div class="col-md-1 sidenav">
        <!--  -->
      </div>
</footer>

</body>
</html>
